{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aa05dbe",
   "metadata": {},
   "source": [
    "# LawStory AI — Judgment PDF to Multi-Scene Explainer Video (Text-Based Prototype)\n",
    "\n",
    "**Primary Goal:** Automatically convert a **court judgment PDF** into a short **multi-scene explainer video** (white text on black background) without manual editing.  \n",
    "**Submitted version:** Works end-to-end **without audio** (multi-scene video generation).  \n",
    "**Audio version (in progress):** Planned voiceover using **ElevenLabs** and asset handling via **Cloudinary**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0664e3ef",
   "metadata": {},
   "source": [
    "## 1. Problem Definition & Objective\n",
    "\n",
    "### a. Selected project track\n",
    "**AI + Automation (LLM + Video Rendering Pipeline)**  \n",
    "This project is built under the AI + Automation track, combining LLM-based legal understanding with an automated video rendering pipeline. The system takes a **judgment PDF as the only input**, extracts key legal information, and converts it into a structured multi-scene explainer video. The process is designed to work without manual editing, manual scriptwriting, or manual video creation.\n",
    "\n",
    "### b. Clear problem statement\n",
    "Legal judgments are long, technical, and difficult to consume quickly. Even with access to the judgment PDF, it takes significant time and effort to identify the **facts, legal issues, arguments from both sides, and the final reasoning of the court**. The problem solved here is: **how to automatically convert a judgment PDF into an easy-to-consume, structured multi-scene video without manual intervention.** Without such a system, users must spend hours reading or depend on inconsistent external summaries.\n",
    "\n",
    "### c. Real-world relevance and motivation\n",
    "- Law students and common people struggle to understand judgments quickly due to complex language, length, and formatting.  \n",
    "- Lawyers, educators, and legal creators need short explainers for education, awareness, and simplified case-law learning.  \n",
    "- Manual summarization + video editing is slow and not scalable.  \n",
    "- This pipeline makes legal content more accessible by converting a judgment into a structured explainer format consumable in minutes.  \n",
    "\n",
    "This project addresses a gap not effectively solved by traditional reading, short notes, or generic summaries and can power **LawStory AI** as a product feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c93c4eb",
   "metadata": {},
   "source": [
    "## 2. Data Understanding & Preparation\n",
    "\n",
    "### a. Dataset source (public / synthetic / collected / API)\n",
    "This project does not use a fixed traditional dataset (like CSVs). It uses **live real-world input** in the form of **judgment PDFs**, including:\n",
    "- Collected / user-provided judgment PDF documents  \n",
    "- Extracted text generated from those PDFs through Make.com scenario processing  \n",
    "\n",
    "So the “data” is unstructured legal text extracted from actual court judgments.\n",
    "\n",
    "### b. Data loading and exploration\n",
    "The data enters the system through Make.com as:\n",
    "- Webhook input containing the judgment PDF URL/file  \n",
    "- HTTP module to fetch/download the PDF  \n",
    "- Custom JS module to extract PDF → text  \n",
    "- Extracted text passed into the AI step  \n",
    "\n",
    "This stage validates:\n",
    "- PDF download success  \n",
    "- Extracted text readability  \n",
    "- Presence of key information (court details, case context)  \n",
    "- Presence of core legal components needed for explanation: facts, issues, arguments, decision, reasoning/ratio  \n",
    "\n",
    "### c. Cleaning, preprocessing, feature engineering\n",
    "Instead of numeric feature engineering, the system uses **LLM-ready preprocessing**:\n",
    "- Ensure extracted text is passed as a clean single input to Gemini  \n",
    "- Enforce predictable JSON output format for automation  \n",
    "- Convert raw judgment text → structured multi-scene JSON video script containing narration, duration_seconds, and visual instructions  \n",
    "\n",
    "### d. Handling missing values or noise (if applicable)\n",
    "Legal PDFs often contain noise:\n",
    "- irregular spacing and line breaks  \n",
    "- repeated headers/footers  \n",
    "- inconsistent formatting  \n",
    "- unclear headings  \n",
    "\n",
    "This is handled by:\n",
    "- relying on Gemini to generate clean structured JSON  \n",
    "- ensuring JSON remains valid and parseable in Make  \n",
    "- designing prompts that still produce complete explainer output even if headings are not explicit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94db189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample extracted text snippet (demo placeholder)\n",
    "judgment_extracted_text = \"\"\"\n",
    "IN THE HIGH COURT OF DELHI AT NEW DELHI\n",
    "Party A v. Party B\n",
    "The dispute concerns residence rights in a property claimed as a shared household.\n",
    "The court examined ownership documents, contributions, and the effect of divorce on residence rights.\n",
    "The appeal was dismissed.\n",
    "\"\"\"\n",
    "\n",
    "print(judgment_extracted_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429d008c",
   "metadata": {},
   "source": [
    "## 3. Model / System Design\n",
    "\n",
    "### a. AI technique used (ML / DL / NLP / LLM / Recommendation / Hybrid)\n",
    "This project uses an **LLM-based NLP pipeline** combined with a video rendering system:\n",
    "- Google Gemini for structured multi-scene script generation  \n",
    "- Shotstack API for rendering the final video  \n",
    "\n",
    "It is a **Hybrid AI + Media Rendering Automation system**.\n",
    "\n",
    "### b. Architecture or pipeline explanation\n",
    "Final working pipeline (multi-scene, one final video URL, no audio):\n",
    "\n",
    "1. Webhook Trigger  \n",
    "   - Receives judgment PDF URL/request from Bubble  \n",
    "\n",
    "2. HTTP Module  \n",
    "   - Downloads/fetches the judgment PDF  \n",
    "\n",
    "3. Custom JS  \n",
    "   - Converts PDF → extracted text  \n",
    "\n",
    "4. Gemini Module  \n",
    "   - Converts extracted judgment text into structured JSON video script  \n",
    "   - Output includes title_frame metadata + scenes[] array  \n",
    "\n",
    "5. Parse JSON module  \n",
    "   - Parses Gemini output so Make can access fields like narration/duration/visual  \n",
    "\n",
    "6. Iterator  \n",
    "   - Iterates over scenes[] and creates one bundle per scene  \n",
    "\n",
    "7. Text Aggregator (critical)  \n",
    "   - Combines all scenes into one “clips array” for Shotstack  \n",
    "\n",
    "8. Shotstack HTTP POST  \n",
    "   - Sends one render request containing all clips in one timeline  \n",
    "   - Returns render ID  \n",
    "\n",
    "9. Shotstack HTTP GET  \n",
    "   - Polls render status until done  \n",
    "   - Returns final video URL  \n",
    "\n",
    "This produces one final MP4 link containing multiple scenes in sequence.\n",
    "\n",
    "### c. Justification of design choices\n",
    "- Gemini is used because legal text is unstructured and requires summarization + structuring.  \n",
    "- JSON output is required for reliable automation mapping in Make.  \n",
    "- Iterator + Aggregator is necessary to combine multiple scenes into one Shotstack timeline.  \n",
    "- Shotstack is used because it supports programmatic video rendering and returns a hosted output URL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3896d8",
   "metadata": {},
   "source": [
    "## 4. Core Implementation\n",
    "\n",
    "### a. Model training / inference logic\n",
    "No training was performed. The pipeline is **inference-only**:\n",
    "- Gemini generates structured script from extracted judgment text  \n",
    "- Shotstack renders the video from structured clips  \n",
    "\n",
    "### b. Prompt engineering (for LLM-based projects)\n",
    "Prompt engineering ensures Gemini output is stable and machine-readable:\n",
    "- Output must be a JSON object only  \n",
    "- Must include scenes as an array  \n",
    "- Each scene includes scene_number, duration_seconds, narration, visual  \n",
    "\n",
    "This was critical because earlier failures occurred when Gemini returned:\n",
    "- extra text before/after JSON  \n",
    "- markdown formatting  \n",
    "- unexpected null values  \n",
    "- unsupported keys  \n",
    "\n",
    "Prompts were refined to enforce plain JSON output with consistent structure.\n",
    "\n",
    "### c. Recommendation or prediction pipeline\n",
    "Not applicable. This is a generation pipeline:\n",
    "Judgment PDF → extracted text → structured scenes → video timeline → final video URL\n",
    "\n",
    "### d. Code must run top-to-bottom without errors\n",
    "In the working version:\n",
    "- Gemini output parses correctly  \n",
    "- Iterator generates multiple scene bundles  \n",
    "- Aggregator combines them into one clips array  \n",
    "- Shotstack POST returns success (201 Created)  \n",
    "- Shotstack GET returns status done + final URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df95c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sample_gemini_output = {\n",
    "  \"title_frame\": {\n",
    "    \"court\": \"High Court of Delhi at New Delhi\",\n",
    "    \"case_title\": \"Party A v. Party B\",\n",
    "    \"year\": \"2025\",\n",
    "    \"citation\": \"Sample Citation\",\n",
    "    \"coram\": \"Sample Coram\"\n",
    "  },\n",
    "  \"scenes\": [\n",
    "    {\n",
    "      \"scene_number\": 1,\n",
    "      \"duration_seconds\": 15,\n",
    "      \"narration\": \"This case explains whether Party A can continue living in a property claimed as a shared household.\",\n",
    "      \"visual\": \"White text on black background: Scene 1 overview\"\n",
    "    },\n",
    "    {\n",
    "      \"scene_number\": 2,\n",
    "      \"duration_seconds\": 20,\n",
    "      \"narration\": \"Party A argued residence rights, while Party B relied on ownership documents and sought possession.\",\n",
    "      \"visual\": \"White text on black background: Scene 2 arguments\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "print(json.dumps(sample_gemini_output, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e15a9f",
   "metadata": {},
   "source": [
    "## 5. Evaluation & Analysis\n",
    "\n",
    "### a. Metrics used (quantitative or qualitative)\n",
    "This system is evaluated using qualitative + functional metrics:\n",
    "- Functional success: Shotstack returns status done  \n",
    "- Final output URL generated successfully  \n",
    "- Scene correctness: multiple scenes appear in the final video  \n",
    "- Timing correctness: each scene duration matches duration_seconds  \n",
    "- Start times accumulate correctly (0, 5, 15, 27…)  \n",
    "- Content quality: narration explains facts, issues, arguments, and reasoning clearly  \n",
    "\n",
    "### b. Sample outputs / predictions\n",
    "The pipeline produces:\n",
    "- One final Shotstack render ID  \n",
    "- One final MP4 video URL (single link)  \n",
    "- Multi-scene text-based video output in correct order  \n",
    "- Consistent readable style (white text on black background)  \n",
    "\n",
    "### c. Performance analysis and limitations\n",
    "**Strengths**\n",
    "- Fully automated end-to-end system  \n",
    "- Works reliably without manual editing  \n",
    "- Multi-scene output is structured correctly  \n",
    "- Produces one combined final video link per judgment  \n",
    "\n",
    "**Limitations (current stage)**\n",
    "- Audio not added yet  \n",
    "- Visuals are minimal and text-based  \n",
    "- Output depends on Gemini summarization consistency  \n",
    "- Video style is simple (text scenes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0072616a",
   "metadata": {},
   "source": [
    "## 6. Ethical Considerations & Responsible AI\n",
    "\n",
    "### a. Bias and fairness considerations\n",
    "Legal summarization can introduce bias by:\n",
    "- emphasizing one party’s narrative  \n",
    "- omitting critical legal reasoning  \n",
    "- oversimplifying disputes  \n",
    "\n",
    "Bias is reduced by:\n",
    "- neutral and factual tone  \n",
    "- avoiding emotional/accusatory language  \n",
    "- using “Party A” and “Party B” instead of assuming relationships  \n",
    "\n",
    "### b. Dataset limitations\n",
    "Inputs vary heavily across judgments:\n",
    "- scanned PDFs may reduce extraction quality  \n",
    "- formatting issues can reduce clarity  \n",
    "- incomplete or non-uniform court orders  \n",
    "\n",
    "### c. Responsible use of AI tools\n",
    "The system is designed for educational understanding and simplified explanation. It should not be treated as a replacement for the original judgment or professional legal interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276cbdcf",
   "metadata": {},
   "source": [
    "## 7. Conclusion & Future Scope\n",
    "\n",
    "### a. Summary of results\n",
    "We successfully built a working Make.com automation that:\n",
    "✅ Takes legal judgment PDF text  \n",
    "✅ Uses Gemini to create a multi-scene script  \n",
    "✅ Iterates over scenes  \n",
    "✅ Aggregates them into one Shotstack timeline  \n",
    "✅ Generates one final video URL with multiple scenes  \n",
    "❌ Audio is not added yet in this version  \n",
    "\n",
    "### b. Possible improvements and extensions\n",
    "Future improvements include:\n",
    "- Add voiceover using ElevenLabs (TTS)  \n",
    "- Add multilingual audio generation  \n",
    "- Add translation features so judgments in any language can be converted into videos in the same language  \n",
    "- Add background visuals/images per scene  \n",
    "- Add subtitles and improved typography  \n",
    "- Add background music at low volume  \n",
    "- Add automatic polling loop for Shotstack GET  \n",
    "- Add JSON repair fallback if Gemini output fails  \n",
    "- Store final URL back to Bubble database for LawStory AI UI\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
